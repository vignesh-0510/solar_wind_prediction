{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f4e313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator\n",
    "import sys\n",
    "sys.path.append('/app')\n",
    "from dataloaders.simple_dataloader import SimpleDataset, collect_sim_paths, get_sims, min_max_normalize, compute_climatology, get_coords, get_cr_dirs\n",
    "from model import make_deeponet\n",
    "from utils.gif_generator import create_gif_from_array\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import toml\n",
    "\n",
    "# from utils.data_utils import read_hdf\n",
    "# from dataloaders.cnn_deeponet_dataloader import DeepONetDataset, get_cr_dirs\n",
    "# from utils.gif_generator import create_gif_from_array \n",
    "# from trainer import train, save_training_results_artifacts\n",
    "from model import DeepONetCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4efd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONetDataset(SimpleDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        cr_list,\n",
    "        v_min=None,\n",
    "        v_max=None,\n",
    "        instruments=None,\n",
    "        scale_up=1,\n",
    "        pos_embedding=None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            data_path=data_path,\n",
    "            cr_list=cr_list,\n",
    "            v_min=v_min,\n",
    "            v_max=v_max,\n",
    "            instruments=instruments,\n",
    "            scale_up=scale_up,\n",
    "            pos_embedding=pos_embedding,\n",
    "        )\n",
    "    def __getitem__(self, index):\n",
    "        cube = self.sims[index]\n",
    "\n",
    "        u_surface = cube[:, 0, :, :]              # (C, H, W)\n",
    "        y_target = cube[0, 1:, :, :]              # (R, H, W)\n",
    "\n",
    "        # Branch input (CNN)\n",
    "        branch_input = torch.tensor(u_surface, dtype=torch.float32)\n",
    "\n",
    "        # Grid\n",
    "        nR, nH, nW = y_target.shape\n",
    "        r = np.arange(1, nR + 1, dtype=np.float32)\n",
    "        h = np.arange(nH, dtype=np.float32)\n",
    "        w = np.arange(nW, dtype=np.float32)\n",
    "\n",
    "        Rg, Hg, Wg = np.meshgrid(r, h, w, indexing=\"ij\")\n",
    "\n",
    "        coords = np.stack([Rg, Hg, Wg], axis=-1).reshape(-1, 3)      # (N,3)\n",
    "        target = y_target.reshape(-1).astype(np.float32)             # (N,)\n",
    "\n",
    "        trunk_input = torch.from_numpy(coords)    # (1, N, 3)\n",
    "        target = torch.from_numpy(target)         # (1, N)\n",
    "\n",
    "        return {\n",
    "            \"branch\": branch_input,        # (C, H, W)\n",
    "            \"trunk\": trunk_input,          # (1, N, 3)\n",
    "            \"target\": target,              # (1, N)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sims)\n",
    "\n",
    "    def get_branch_input_dims(self):\n",
    "        C, H, W = self.sims.shape[1], self.sims.shape[3], self.sims.shape[4]\n",
    "        return C * H * W\n",
    "\n",
    "    def get_trunk_input_dims(self):\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7d7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58410660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full_grid_in_chunks(model, branch, coords, H, W, chunk_size=32768, accelerator=None):\n",
    "    \"\"\"\n",
    "    model: DeepONet\n",
    "    branch: (1, C, H, W)\n",
    "    coords: (N, 3)\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    branch = branch.to(device)\n",
    "    coords = coords.to(device)\n",
    "\n",
    "    N = coords.shape[0]\n",
    "    preds = torch.zeros(N, device=device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, N, chunk_size):\n",
    "            end = min(start + chunk_size, N)\n",
    "            coords_chunk = coords[start:end].unsqueeze(0)        # (1, n_chunk, 3)\n",
    "\n",
    "            if accelerator:\n",
    "                with accelerator.autocast():\n",
    "                    y_chunk = model(branch, coords_chunk)         # (1, n_chunk)\n",
    "            else:\n",
    "                y_chunk = model(branch, coords_chunk)\n",
    "\n",
    "            preds[start:end] = y_chunk[0]\n",
    "\n",
    "    return preds.reshape(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6abd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading simulations: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.54it/s]\n",
      "Loading simulations: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 33/33 [00:09<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/app/src/DeepONetCNN/config.toml', 'r') as f:\n",
    "    config = toml.load(f)\n",
    "\n",
    "DATA_DIR = config['train_params']['data_dir']\n",
    "BASE_DIR = config['train_params']['base_dir']\n",
    "batch_size = config['train_params']['batch_size']\n",
    "\n",
    "\n",
    "model_type = config['model_params']['model_type']\n",
    "scale_up = config['model_params']['scale_up']\n",
    "loss_fn_str = config['model_params']['loss_fn']\n",
    "pos_embedding = config['model_params']['pos_embedding']\n",
    "trunk_sample_size = config['model_params']['trunk_sample_size']\n",
    "branch_layers = config['model_params'].get('branch_layers', [128,128,128,128])\n",
    "trunk_layers = config['model_params'].get('trunk_layers', [128,128,128,128])\n",
    "job_id = \"2025_11_20__080328\"\n",
    "\n",
    "cr_dirs = get_cr_dirs(DATA_DIR)\n",
    "split_ix = int(len(cr_dirs) * 0.8)\n",
    "cr_train, cr_val = cr_dirs[:10], cr_dirs[split_ix:]\n",
    "cr_val = cr_val[::len(cr_val)//10]\n",
    "train_dataset = DeepONetDataset(DATA_DIR, cr_train, scale_up=scale_up, pos_embedding=pos_embedding)   \n",
    "val_dataset = DeepONetDataset(\n",
    "    DATA_DIR,\n",
    "    cr_val,\n",
    "    scale_up=scale_up,\n",
    "    v_min=train_dataset.v_min,\n",
    "    v_max=train_dataset.v_max,\n",
    "    pos_embedding=pos_embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318ceca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepONetCNN(\n",
      "  (branch): CNNBranch(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): ReLU()\n",
      "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (mix): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (trunk): TrunkMLP(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (7): Tanh()\n",
      "      (8): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA driver version is insufficient for CUDA runtime version\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nDevice-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     38\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m---> 41\u001b[0m gen_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m gen_cpu\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# optional, for reproducibility    # Make DataLoaders use CPU RNG to avoid device mismatch\u001b[39;00m\n\u001b[1;32m     44\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     45\u001b[0m     val_dataset,\n\u001b[1;32m     46\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     generator\u001b[38;5;241m=\u001b[39mgen_cpu,\n\u001b[1;32m     50\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA driver version is insufficient for CUDA runtime version\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nDevice-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers."
     ]
    }
   ],
   "source": [
    "device = torch.device(f\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "radii, thetas, phis = train_dataset.get_grid_points()\n",
    "\n",
    "if loss_fn_str == \"l2\":\n",
    "    loss_fn = LpLoss(d=2, p=2)\n",
    "elif loss_fn_str == \"h1\":\n",
    "    loss_fn = H1LossSpherical(r_grid=radii[1:], theta_grid=thetas, phi_grid=phis)\n",
    "elif loss_fn_str == \"h1mae\":\n",
    "    loss_fn = H1LossSphericalMAE(r_grid=radii[1:], theta_grid=thetas, phi_grid=phis)\n",
    "elif loss_fn_str == \"mse\":\n",
    "    loss_fn = nn.MSELoss()\n",
    "else:\n",
    "    raise ValueError(\"unsupported loss function\")\n",
    "\n",
    "out_path = os.path.join(BASE_DIR, model_type, job_id)\n",
    "\n",
    "os.makedirs(os.path.join(out_path, 'result_gifs'), exist_ok=True)\n",
    "\n",
    "if pos_embedding == 'pt':\n",
    "    in_channels = 4\n",
    "elif pos_embedding == 'ptr':\n",
    "    raise ValueError('radii embedding is the same in full channel and is not supported here')\n",
    "elif pos_embedding is None or pos_embedding == False:\n",
    "    in_channels = 1\n",
    "else:\n",
    "    raise ValueError('wrong pos embedding')\n",
    "\n",
    "model = DeepONetCNN(\n",
    "    in_channels=in_channels,\n",
    "    trunk_in_dim=3,\n",
    "    latent_dim=128,\n",
    "    trunk_hidden=trunk_layers,\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('./best_model.pt', map_location='cpu', weights_only=True))\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "batch_size = 6\n",
    "\n",
    "\n",
    "gen_cpu = torch.Generator(device=\"cuda\")\n",
    "gen_cpu.manual_seed(42)  # optional, for reproducibility    # Make DataLoaders use CPU RNG to avoid device mismatch\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    "    generator=gen_cpu,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "step = 1\n",
    "for batch in tqdm(train_loader):\n",
    "    u = batch[\"branch\"].to(device)     # (B, C*H*W)   or (B, D_branch)\n",
    "    coords = batch[\"trunk\"].to(device) # (B, N, 3)    or sometimes (N, 3) broadcasted\n",
    "    y_true = batch[\"target\"].to(device) # (B, N)\n",
    "\n",
    "    B = y_true.shape[0]\n",
    "    R,H,W = val_dataset.sims.shape[2:]\n",
    "    pred = model(u, coords)     # (B, N)\n",
    "\n",
    "    # ---- denormalize for metrics (matches your code path) ----\n",
    "    real_y   = y_true * (train_dataset.v_max - train_dataset.v_min) + train_dataset.v_min\n",
    "    real_pred= pred    * (train_dataset.v_max - train_dataset.v_min) + train_dataset.v_min\n",
    "    real_y   = real_y * 481.3711\n",
    "    real_pred= real_pred * 481.3711\n",
    "    real_y = real_y.view(B, R, H, W)\n",
    "    real_pred = real_pred.view(B, R, H, W)\n",
    "    for i in range(len(B)):\n",
    "        input_file_name = f'input_step_{step}.gif'\n",
    "        output_file_name = f'output_step_{step}.gif'\n",
    "        create_gif_from_array(real_y.transpose(1,2,0), os.path.join(out_path, 'result_gifs'), file_name=input_file_name)\n",
    "        create_gif_from_array(real_pred.transpose(1,2,0), os.path.join(out_path, 'result_gifs'), file_name=input_file_name)\n",
    "        step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55aea163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124, https://pypi.ngc.nvidia.com\n",
      "Collecting torch==2.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.4.0%2Bcu124-cp310-cp310-linux_x86_64.whl (797.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.0a0)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.99 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (24.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.99 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.4/883.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.99 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.4.2.65 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.2.65-py3-none-manylinux2014_x86_64.whl (363.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.0.44 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.0.44-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.119 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.119-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.0.99 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.0.99-py3-none-manylinux2014_x86_64.whl (128.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.0.142 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.0.142-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.99 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.99 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.32.3)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.19.1%2Bcu124-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.19.0%2Bcu124-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.1.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.1%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.0%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.2.0\n",
      "\u001b[2K    Uninstalling triton-3.2.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.2.0━━━━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.4.1275\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.4.127:━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.4.127━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.4.127[0m \u001b[32m 1/15\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.4.127:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127━\u001b[0m \u001b[32m 1/15\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/15\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.5.147\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.5.147:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.5.147━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.1.3━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.1.3:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127 \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127━━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.1270m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.4.1270m \u001b[32m 7/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.4.5.8━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.4.5.8:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu120m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.3.1.1700m \u001b[32m 9/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.3.1.170:━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.1.9:0m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.6.0[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.6.0:━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.6.00m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.17.0a00m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.17.0a0:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m12/15\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.17.0a0╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m13/15\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [torchaudio]5\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch-tensorrt 2.2.0a0 requires torch<2.4.0,>=2.1.0.dev, but you have torch 2.4.0+cu124 which is incompatible.\n",
      "torchtext 0.17.0a0 requires torch==2.2.0a0+81ea7a4, but you have torch 2.4.0+cu124 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.2.65 nvidia-cuda-cupti-cu12-12.4.99 nvidia-cuda-nvrtc-cu12-12.4.99 nvidia-cuda-runtime-cu12-12.4.99 nvidia-cufft-cu12-11.2.0.44 nvidia-curand-cu12-10.3.5.119 nvidia-cusolver-cu12-11.6.0.99 nvidia-cusparse-cu12-12.3.0.142 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.4.99 torch-2.4.0+cu124 torchaudio-2.4.0+cu124 torchvision-0.19.0+cu124 triton-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.4.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aff8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA version: 12.4\n",
      "Compiled With: 12.4\n",
      "CUDA available: False\n",
      "Device Count: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA available:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice Count:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[0;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor is ok:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "print(\"Torch CUDA version:\", torch.version.cuda)\n",
    "print(\"Compiled With:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device Count:\", torch.cuda.device_count())\n",
    "\n",
    "x = torch.randn(1).cuda()\n",
    "print(\"Tensor is ok:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66591dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
