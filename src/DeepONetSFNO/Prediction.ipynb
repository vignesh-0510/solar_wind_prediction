{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f4e313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator\n",
    "import sys\n",
    "sys.path.append('/app')\n",
    "from dataloaders.dataloaders.simple_dataloader import SimpleDataset, collect_sim_paths, get_sims, min_max_normalize, compute_climatology, get_coords, get_cr_dirs\n",
    "from model import make_deeponet\n",
    "from utils.gif_generator import create_gif_from_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efd913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONetDataset(SimpleDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        cr_list,\n",
    "        v_min=None,\n",
    "        v_max=None,\n",
    "        instruments=None,\n",
    "        scale_up=1,\n",
    "        pos_embedding = None,\n",
    "        trunk_sample_size=32768,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            data_path=data_path,\n",
    "            cr_list=cr_list,\n",
    "            v_min=v_min,\n",
    "            v_max=v_max,\n",
    "            instruments=instruments,\n",
    "            scale_up=scale_up,\n",
    "            pos_embedding=pos_embedding,\n",
    "        )\n",
    "        self.trunk_sample_size = trunk_sample_size\n",
    "        # self.sim_paths = collect_sim_paths(data_path, cr_list, instruments)\n",
    "        # sims, _ = get_sims(self.sim_paths, scale_up, pos_embedding)\n",
    "        # sims, self.v_min, self.v_max = min_max_normalize(sims, v_min, v_max)\n",
    "        # self.sims = sims\n",
    "        # self.climatology = compute_climatology(sims[:, 0, 1:, :, :], scale_up)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cube = self.sims[index]\n",
    "\n",
    "        u_surface = cube[:, 0, :, :]   # (C, H, W)\n",
    "        y_target = cube[0, 1:, :, :] \n",
    "\n",
    "        # Flatten surface for branch input\n",
    "        branch_input = torch.tensor(u_surface, dtype=torch.float32).reshape(-1)\n",
    "        \n",
    "        # Fast random sampling of trunk points\n",
    "        nR, nH, nW = y_target.shape\n",
    "        idx_r = np.random.randint(0, nR, size=self.trunk_sample_size)\n",
    "        idx_h = np.random.randint(0, nH, size=self.trunk_sample_size)\n",
    "        idx_w = np.random.randint(0, nW, size=self.trunk_sample_size)\n",
    "        \n",
    "        \n",
    "        self.r = np.arange(1, nR + 1, dtype=np.float32)\n",
    "        self.h = np.arange(nH, dtype=np.float32)\n",
    "        self.w = np.arange(nW, dtype=np.float32)\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"branch\": branch_input,   # (H * W * C,)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sims)\n",
    "\n",
    "    def get_min_max(self):\n",
    "        return {\"v_min\": float(self.v_min), \"v_max\": float(self.v_max)}\n",
    "\n",
    "    def get_grid_points(self):\n",
    "        return get_coords(self.sim_paths[0])\n",
    "\n",
    "    def get_branch_input_dims(self):\n",
    "        C, H, W = self.sims.shape[1], self.sims.shape[3], self.sims.shape[4]\n",
    "        return C * H * W\n",
    "        \n",
    "    def get_trunk_input_dims(self):\n",
    "        return 3  # r, theta, phi\n",
    "    def get_grid_points_dim(self):\n",
    "        return self.r, self.h, self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2c7d7a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 108\u001b[0m\n\u001b[1;32m     97\u001b[0m cr_dirs \u001b[38;5;241m=\u001b[39m get_cr_dirs(DATA)\n\u001b[1;32m     98\u001b[0m cr_eval \u001b[38;5;241m=\u001b[39m cr_dirs[:\u001b[38;5;241m32\u001b[39m]   \u001b[38;5;66;03m# choose some CRs\u001b[39;00m\n\u001b[1;32m    100\u001b[0m preds, targets, shape, dataset \u001b[38;5;241m=\u001b[39m run_inference(\n\u001b[1;32m    101\u001b[0m     model_path\u001b[38;5;241m=\u001b[39mMODEL,\n\u001b[1;32m    102\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mDATA,\n\u001b[1;32m    103\u001b[0m     cr_list\u001b[38;5;241m=\u001b[39mcr_eval,\n\u001b[1;32m    104\u001b[0m     out_dir\u001b[38;5;241m=\u001b[39mout_dir,\n\u001b[1;32m    105\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m    106\u001b[0m     branch_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m],\n\u001b[1;32m    107\u001b[0m     trunk_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m],\n\u001b[0;32m--> 108\u001b[0m     pos_embedding\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mpos_embedding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mdataset\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m     trunk_sample_size\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtrunk_sample_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrunk_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m make_gifs(preds, targets, shape, dataset, out_dir)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGIFs created in\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def make_gifs(preds, targets, shape, dataset, out_dir):\n",
    "    C, H, W = shape\n",
    "\n",
    "    # reshape flat to (frames, H, W)\n",
    "    preds_grid = preds.reshape(-1, H, W)\n",
    "    targets_grid = targets.reshape(-1, H, W)\n",
    "    error_grid = np.abs(preds_grid - targets_grid)\n",
    "\n",
    "    np.save(os.path.join(out_dir, \"preds_grid.npy\"), preds_grid)\n",
    "    np.save(os.path.join(out_dir, \"targets_grid.npy\"), targets_grid)\n",
    "    np.save(os.path.join(out_dir, \"error_grid.npy\"), error_grid)\n",
    "\n",
    "    # make gifs\n",
    "    create_gif_from_array(preds_grid,   os.path.join(out_dir, \"preds.gif\"))\n",
    "    create_gif_from_array(targets_grid, os.path.join(out_dir, \"targets.gif\"))\n",
    "    create_gif_from_array(error_grid,   os.path.join(out_dir, \"error.gif\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # paths\n",
    "    MODEL = \"/app/output/DeepONetCNN/2025_11_20__074500/best_model.pt\"\n",
    "    DATA = \"/app/data\"\n",
    "\n",
    "    out_dir = \"./eval_outputs\"\n",
    "\n",
    "    cr_dirs = get_cr_dirs(DATA)\n",
    "    cr_eval = cr_dirs[:32]   # choose some CRs\n",
    "\n",
    "    preds, targets, shape, dataset = run_inference(\n",
    "        model_path=MODEL,\n",
    "        data_dir=DATA,\n",
    "        cr_list=cr_eval,\n",
    "        out_dir=out_dir,\n",
    "        batch_size=8,\n",
    "        branch_layers=[128,128,128,128],\n",
    "        trunk_layers=[128,128,128,128],\n",
    "        pos_embedding=dataset.pos_embedding if hasattr(dataset, \"pos_embedding\") else None,\n",
    "        trunk_sample_size=dataset.trunk_sample_size if hasattr(dataset, \"trunk_sample_size\") else None,\n",
    "    )\n",
    "\n",
    "    make_gifs(preds, targets, shape, dataset, out_dir)\n",
    "    print(\"GIFs created in\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58410660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full_grid_in_chunks(model, branch, coords, H, W, chunk_size=32768, accelerator=None):\n",
    "    \"\"\"\n",
    "    model: DeepONet\n",
    "    branch: (1, C, H, W)\n",
    "    coords: (N, 3)\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    branch = branch.to(device)\n",
    "    coords = coords.to(device)\n",
    "\n",
    "    N = coords.shape[0]\n",
    "    preds = torch.zeros(N, device=device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, N, chunk_size):\n",
    "            end = min(start + chunk_size, N)\n",
    "            coords_chunk = coords[start:end].unsqueeze(0)        # (1, n_chunk, 3)\n",
    "\n",
    "            if accelerator:\n",
    "                with accelerator.autocast():\n",
    "                    y_chunk = model(branch, coords_chunk)         # (1, n_chunk)\n",
    "            else:\n",
    "                y_chunk = model(branch, coords_chunk)\n",
    "\n",
    "            preds[start:end] = y_chunk[0]\n",
    "\n",
    "    return preds.reshape(H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ceca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Document helper.....')\n",
    "    parser.add_argument('--ngpu', type=int, default=0, help='set the gpu on which the model will run')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    ngpu      = args.ngpu\n",
    "    \n",
    "    with open('/app/src/DeepONet/config.toml', 'r') as f:\n",
    "        config = toml.load(f)\n",
    "    \n",
    "    DATA_DIR = config['train_params']['data_dir']\n",
    "    BASE_DIR = config['train_params']['base_dir']\n",
    "    batch_size = config['train_params']['batch_size']\n",
    "\n",
    "\n",
    "    model_type = config['model_params']['model_type']\n",
    "    scale_up = config['model_params']['scale_up']\n",
    "    loss_fn_str = config['model_params']['loss_fn']\n",
    "    pos_embedding = config['model_params']['pos_embedding']\n",
    "    trunk_sample_size = config['model_params']['trunk_sample_size']\n",
    "    branch_layers = config['model_params'].get('branch_layers', [128,128,128,128])\n",
    "    trunk_layers = config['model_params'].get('trunk_layers', [128,128,128,128])\n",
    "\n",
    "    cr_dirs = get_cr_dirs(DATA_DIR)\n",
    "    split_ix = int(len(cr_dirs) * 0.8)\n",
    "    cr_train, cr_val = cr_dirs[:split_ix], cr_dirs[split_ix:]\n",
    "    cr_val = cr_val[::len(cr_val)//10]\n",
    "    train_dataset = DeepONetDataset(DATA_DIR, cr_train, scale_up=scale_up, pos_embedding=pos_embedding, trunk_sample_size=trunk_sample_size)   \n",
    "    val_dataset = DeepONetDataset(\n",
    "        DATA_DIR,\n",
    "        cr_val,\n",
    "        scale_up=scale_up,\n",
    "        v_min=train_dataset.v_min,\n",
    "        v_max=train_dataset.v_max,\n",
    "        pos_embedding=pos_embedding,\n",
    "        trunk_sample_size=trunk_sample_size\n",
    "    )\n",
    "    device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    radii, thetas, phis = train_dataset.get_grid_points()\n",
    "\n",
    "    if loss_fn_str == \"l2\":\n",
    "        loss_fn = LpLoss(d=2, p=2)\n",
    "    elif loss_fn_str == \"h1\":\n",
    "        loss_fn = H1LossSpherical(r_grid=radii[1:], theta_grid=thetas, phi_grid=phis)\n",
    "    elif loss_fn_str == \"h1mae\":\n",
    "        loss_fn = H1LossSphericalMAE(r_grid=radii[1:], theta_grid=thetas, phi_grid=phis)\n",
    "    elif loss_fn_str == \"mse\":\n",
    "        loss_fn = nn.MSELoss()\n",
    "    else:\n",
    "        raise ValueError(\"unsupported loss function\")\n",
    "\n",
    "    out_path = os.path.join(BASE_DIR, model_type, job_id)\n",
    "\n",
    "        \n",
    "    if pos_embedding == 'pt':\n",
    "        in_channels = 4\n",
    "    elif pos_embedding == 'ptr':\n",
    "        raise ValueError('radii embedding is the same in full channel and is not supported here')\n",
    "    elif pos_embedding is None:\n",
    "        in_channels = 1\n",
    "    else:\n",
    "        raise ValueError('wrong pos embedding')\n",
    "    \n",
    "    model = DeepONet(\n",
    "        in_channels=in_channels,\n",
    "        trunk_in_dim=3,\n",
    "        latent_dim=128,\n",
    "        trunk_hidden=trunk_layers,\n",
    "    ).to(device)\n",
    "    \n",
    "    print(model)\n",
    "    batch_size = 6\n",
    "    \n",
    "\n",
    "    gen_cpu = torch.Generator(device=\"cuda\")\n",
    "    gen_cpu.manual_seed(42)  # optional, for reproducibility    # Make DataLoaders use CPU RNG to avoid device mismatch\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        generator=gen_cpu,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(BASE_DIR), map_location='cpu', weights_only=True))\n",
    "    model = model.to(device)\n",
    "\n",
    "    torch.save(best_state_dict, os.path.join(out_path, \"best_model.pt\"))\n",
    "    if run is not None:\n",
    "        artifact = wandb.Artifact(\n",
    "            name='best_model',\n",
    "            type='model',\n",
    "            description='best model after training'\n",
    "        )\n",
    "        artifact.add_file(os.path.join(out_path, f\"best_model.pt\"))\n",
    "        run.log_artifact(artifact)\n",
    "\n",
    "    filename = f\"best_epoch-{best_epoch}.txt\"\n",
    "    with open(\n",
    "        os.path.join(out_path, filename), \"w\", encoding=\"utf-8\"\n",
    "    ) as f:\n",
    "        f.write(f\"best_epoch: {best_epoch}\")\n",
    "    if run is not None:\n",
    "        artifact = wandb.Artifact(\n",
    "            name='best_epoch',\n",
    "            type='evaluation',\n",
    "            description='epoch with lowest validation loss'\n",
    "        )\n",
    "        artifact.add_file(os.path.join(out_path, filename))\n",
    "        run.log_artifact(artifact)\n",
    "\n",
    "    save_training_results_artifacts(run, out_path, training_results)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
